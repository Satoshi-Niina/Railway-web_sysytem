import { Pool } from "pg"

let pool: Pool | null = null

export function resetPool() {
  if (pool) {
    console.log("Resetting database pool...")
    pool.end().catch(err => console.error("Error closing pool:", err))
    pool = null
  }
}

export function getPool() {
  if (!pool) {
    // ã‚µãƒ¼ãƒï¿½Eã‚µã‚¤ãƒ‰ã§ã®ã¿ç’°å¢Eï¿½ï¿½æ•°ã‚’ï¿½Eèª­ã¿è¾¼ã¿
    if (!process.env.DATABASE_URL) {
      try {
        const fs = require('fs');
        const path = require('path');
        const dotenv = require('dotenv');
        
        // ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆï¿½E.env.developmentã‚’æ¢ãE        // Next.jsã®ãƒ“ãƒ«ãƒ‰æ™‚ã¯client/ãŒã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        const possiblePaths = [
          path.resolve(process.cwd(), '../.env.development'),  // clientã‹ã‚‰ä¸€ã¤ä¸E          path.resolve(process.cwd(), '.env.development'),    // ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        ];
        
        for (const envPath of possiblePaths) {
          if (fs.existsSync(envPath)) {
            console.log("âœELoading environment variables from:", envPath);
            dotenv.config({ path: envPath });
            break;
          }
        }
      } catch (e) {
        console.error("âš ï¿½Eï¿½EFailed to load .env.development:", e)
      }
    }

    const databaseUrl = process.env.DATABASE_URL || process.env.POSTGRES_URL

    if (!databaseUrl) {
      console.error("âEDATABASE_URL is not set!")
      return null
    }

    console.log("âœEConnecting to PostgreSQL:", databaseUrl.replace(/:[^:@]+@/, ':****@'))

    try {
      pool = new Pool({
        connectionString: databaseUrl,
        ssl: false,
        max: 10,
        min: 2,
        idleTimeoutMillis: 30000,
        connectionTimeoutMillis: 10000,
        allowExitOnIdle: false,
      })

      // æ¥ç¶šã‚¨ãƒ©ãƒ¼ã®ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
      pool.on('error', (err) => {
        console.error('âEUnexpected database pool error:', err)
        console.error('Error code:', err.code)
        console.error('Error message:', err.message)
      })

      pool.on('connect', async (client) => {
        console.log('âœENew database connection established')
        // æ¥ç¶šæ™‚ã«search_pathã‚’è¨­å®E        try {
          await client.query('SET search_path TO master_data, operations, inspections, maintenance, public')
          console.log('âœEsearch_path set to: master_data, operations, inspections, maintenance, public')
        } catch (err) {
          console.error('âš ï¿½Eï¿½EFailed to set search_path:', err)
        }
      })

      pool.on('remove', () => {
        console.log('âš ï¿½Eï¿½EDatabase connection removed from pool')
      })

      console.log("âœEDatabase pool created successfully")
    } catch (error) {
      console.error("âEFailed to create database pool:", error)
      return null
    }
  }

  return pool
}

export async function query(text: string, params?: any[]) {
  let pool = getPool()
  
  if (!pool) {
    console.error("Database pool is not initialized")
    console.error("DATABASE_URL:", process.env.DATABASE_URL ? "Set" : "Not set")
    throw new Error("Database not configured")
  }

  let client;
  let retryCount = 0;
  const maxRetries = 2;

  while (retryCount <= maxRetries) {
    try {
      client = await pool.connect()
      const result = await client.query(text, params)
      return result
    } catch (error: any) {
      console.error(`Database query error (attempt ${retryCount + 1}/${maxRetries + 1}):`, error)
      
      // æ¥ç¶šã‚¨ãƒ©ãƒ¼ã®å ´åˆã€ï¿½Eãƒ¼ãƒ«ã‚’ãƒªã‚»ãƒEï¿½ï¿½ã—ã¦å†æ¥ç¶šã‚’è©¦ã¿ã‚E      if (retryCount < maxRetries && (error.code === 'ECONNRESET' || error.code === '57P01' || error.message?.includes('Client has encountered a connection error'))) {
        console.log("Connection error detected, resetting pool and retrying...")
        resetPool()
        pool = getPool()
        retryCount++
        await new Promise(resolve => setTimeout(resolve, 1000)) // 1ç§’å¾Eï¿½ï¿½E        continue
      }
      
      console.error("Query:", text)
      console.error("Params:", params)
      throw error
    } finally {
      if (client) {
        client.release()
      }
    }
  }

  throw new Error("Max retries exceeded")
}

export async function transaction(callback: (client: any) => Promise<any>) {
  const pool = getPool()
  
  if (!pool) {
    throw new Error("Database not configured")
  }
  
  const client = await pool.connect()

  try {
    await client.query("BEGIN")
    const result = await callback(client)
    await client.query("COMMIT")
    return result
  } catch (error) {
    await client.query("ROLLBACK")
    throw error
  } finally {
    client.release()
  }
}

// ãƒEï¿½Eã‚¿ãƒ™ï¿½Eã‚¹æ¥ç¶šãƒ†ã‚¹ãƒEexport async function testConnection() {
  try {
    const result = await query("SELECT NOW()")
    console.log("Database connection successful:", result.rows[0])
    return true
  } catch (error) {
    console.error("Database connection failed:", error)
    return false
  }
}

// æ¥ç¶šï¿½Eãƒ¼ãƒ«ã®çŠ¶æ…‹ã‚’å–å¾Eexport function getPoolStatus() {
  if (!pool) return null
  return {
    totalCount: pool.totalCount,
    idleCount: pool.idleCount,
    waitingCount: pool.waitingCount,
  }
}

// ãƒEï¿½Eã‚¿ãƒ™ï¿½Eã‚¹ã‚¿ã‚¤ãƒ—ã‚’å–å¾Eexport function getDatabaseType(): string {
  const databaseUrl = process.env.DATABASE_URL || process.env.POSTGRES_URL
  if (databaseUrl && databaseUrl.startsWith('postgresql://')) {
    return "postgresql"
  }
  return "mock"
}

// ãƒEï¿½Eã‚¿ãƒ™ï¿½Eã‚¹æƒEï¿½ï¿½ã‚’å–å¾—ï¼ˆå®Ÿæ¸¬å€¤ï¿½Eï¿½Eexport async function getDatabaseInfo() {
  try {
    const pool = getPool()
    
    if (!pool) {
      return null
    }
    
    // PostgreSQLãƒï¿½Eã‚¸ãƒ§ãƒ³
    const versionResult = await query("SELECT version()")
    
    // ãƒEï¿½Eã‚¿ãƒ™ï¿½Eã‚¹ã‚µã‚¤ã‚ºï¿½Eï¿½å®Ÿæ¸¬ï¿½Eï¿½E    const sizeResult = await query(`
      SELECT pg_database_size(current_database()) as size
    `)
    
    // ãƒEï¿½Eãƒ–ãƒ«ã‚µã‚¤ã‚ºã®è©³ç´°ï¿½Eï¿½å®Ÿæ¸¬ï¿½Eï¿½E    const tableSizeResult = await query(`
      SELECT 
        schemaname,
        tablename,
        pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size,
        pg_total_relation_size(schemaname||'.'||tablename) as size_bytes
      FROM pg_tables
      WHERE schemaname NOT IN ('pg_catalog', 'information_schema')
      ORDER BY size_bytes DESC
      LIMIT 10
    `)
    
    // æ¥ç¶šæ•°ï¿½Eï¿½å®Ÿæ¸¬ï¿½Eï¿½E    const connectionsResult = await query(`
      SELECT count(*) as count FROM pg_stat_activity
    `)
    
    // ã‚¢ãƒEï¿½Eã‚¿ã‚¤ãƒ ï¿½Eï¿½å®Ÿæ¸¬ï¿½Eï¿½E    const uptimeResult = await query(`
      SELECT EXTRACT(EPOCH FROM (now() - pg_postmaster_start_time())) as uptime
    `)
    
    // ãƒEï¿½ï¿½ã‚¹ã‚¯ä½¿ç”¨çEï¿½ï¿½å®Ÿæ¸¬ - ãƒEï¿½Eã‚¿ãƒEï¿½ï¿½ãƒ¬ã‚¯ãƒˆãƒªã®ã‚µã‚¤ã‚ºï¿½Eï¿½E    const diskUsageResult = await query(`
      SELECT 
        pg_database_size(current_database()) as used,
        (SELECT setting::bigint FROM pg_settings WHERE name = 'shared_buffers') * 
        (SELECT setting::bigint FROM pg_settings WHERE name = 'block_size') as allocated
    `)
    
    const version = versionResult.rows[0]?.version || "Unknown"
    const sizeBytes = parseInt(sizeResult.rows[0]?.size || 0)
    const connections = connectionsResult.rows[0]?.count || 0
    const uptimeSeconds = uptimeResult.rows[0]?.uptime || 0
    const diskUsed = parseInt(diskUsageResult.rows[0]?.used || 0)
    const diskAllocated = parseInt(diskUsageResult.rows[0]?.allocated || 0)
    
    // ãƒï¿½Eã‚¸ãƒ§ãƒ³æ–Eï¿½ï¿½ï¿½Eã‹ã‚‰PostgreSQLãƒï¿½Eã‚¸ãƒ§ãƒ³ç•ªå·ã‚’æŠ½å‡º
    const versionMatch = version.match(/PostgreSQL (\d+\.\d+)/)
    const postgresVersion = versionMatch ? `PostgreSQL ${versionMatch[1]}` : "PostgreSQL"
    
    // ã‚¢ãƒEï¿½Eã‚¿ã‚¤ãƒ ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒE    const days = Math.floor(uptimeSeconds / 86400)
    const hours = Math.floor((uptimeSeconds % 86400) / 3600)
    const minutes = Math.floor((uptimeSeconds % 3600) / 60)
    const uptime = `${days}æ—¥ ${hours}æ™‚é–“ ${minutes}åˆE
    
    // ã‚µã‚¤ã‚ºã‚’GB/MBå˜ä½ã«å¤‰æ›
    const sizeGB = (sizeBytes / (1024 * 1024 * 1024))
    const sizeMB = (sizeBytes / (1024 * 1024))
    const sizeFormatted = sizeGB >= 1 ? `${sizeGB.toFixed(2)} GB` : `${sizeMB.toFixed(2)} MB`
    
    // ãƒEï¿½ï¿½ã‚¹ã‚¯ä½¿ç”¨çEï¿½ï¿½è¨ˆç®E    const diskUsagePercent = diskAllocated > 0 ? 
      Math.min(100, ((diskUsed / diskAllocated) * 100)) : 0
    
    return {
      version: postgresVersion,
      size: sizeFormatted,
      sizeBytes: sizeBytes,
      connections: parseInt(connections),
      uptime,
      diskUsagePercent: diskUsagePercent.toFixed(1),
      tableSizes: tableSizeResult.rows.map((row: any) => ({
        schema: row.schemaname,
        table: row.tablename,
        size: row.size,
        sizeBytes: parseInt(row.size_bytes)
      }))
    }
  } catch (error) {
    console.error("Failed to get database info:", error)
    return null
  }
}

// app_resource_routingã®ã‚­ãƒ£ãƒEï¿½ï¿½ãƒ¥
interface ResourceRouting {
  logical_resource_name: string
  physical_schema: string
  physical_table: string
}

let resourceRoutingCache: Map<string, ResourceRouting> | null = null
let routingCacheLoadTime: number | null = null
const CACHE_TTL = 60000 // 60ç§E
// app_resource_routingã‹ã‚‰ãƒ«ãƒ¼ãƒEï¿½ï¿½ãƒ³ã‚°æƒEï¿½ï¿½ã‚’èª­ã¿è¾¼ã¿
async function loadResourceRouting(): Promise<void> {
  try {
    const pool = getPool()
    if (!pool) {
      console.warn('âš ï¿½Eï¿½EDatabase pool not available, using fallback routing')
      return
    }

    // ã‚­ãƒ£ãƒEï¿½ï¿½ãƒ¥ãŒæœ‰åŠ¹ãªå ´åˆï¿½Eã‚¹ã‚­ãƒEï¿½E
    const now = Date.now()
    if (resourceRoutingCache && routingCacheLoadTime && (now - routingCacheLoadTime) < CACHE_TTL) {
      return
    }

    console.log('ğŸ“‹ Loading resource routing from app_resource_routing...')
    const result = await query(
      'SELECT logical_resource_name, physical_schema, physical_table FROM public.app_resource_routing WHERE is_active = true'
    )
    
    resourceRoutingCache = new Map()
    for (const row of result.rows) {
      resourceRoutingCache.set(row.logical_resource_name, {
        logical_resource_name: row.logical_resource_name,
        physical_schema: row.physical_schema,
        physical_table: row.physical_table,
      })
    }
    
    routingCacheLoadTime = now
    console.log(`âœELoaded ${resourceRoutingCache.size} resource routes`)
  } catch (error) {
    console.error('âEFailed to load resource routing:', error)
    // ã‚¨ãƒ©ãƒ¼ã®å ´åˆï¿½Eãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½¿ç”¨
  }
}

// ãƒªã‚½ãƒ¼ã‚¹åã‹ã‚‰ã‚¹ã‚­ãƒ¼ãƒã¨ãƒEï¿½Eãƒ–ãƒ«ã‚’è§£æ±º
export async function resolveResource(logicalResourceName: string): Promise<{ schema: string; table: string }> {
  // ãƒ«ãƒ¼ãƒEï¿½ï¿½ãƒ³ã‚°æƒEï¿½ï¿½ã‚’èª­ã¿è¾¼ã¿ï¿½Eï¿½ï¿½Eå›ã¾ãŸï¿½Eã‚­ãƒ£ãƒEï¿½ï¿½ãƒ¥æœŸé™åˆEï¿½ï¿½ã®å ´åˆï¼E  await loadResourceRouting()
  
  // ã‚­ãƒ£ãƒEï¿½ï¿½ãƒ¥ã‹ã‚‰æ¤œç´¢
  if (resourceRoutingCache?.has(logicalResourceName)) {
    const routing = resourceRoutingCache.get(logicalResourceName)!
    return {
      schema: routing.physical_schema,
      table: routing.physical_table,
    }
  }
  
  // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒï¿½Eãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒãƒƒãƒ”ãƒ³ã‚°
  return getSchemaForTableFallback(logicalResourceName)
}

// ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ãƒEï¿½Eãƒ–ãƒ«åã‹ã‚‰ã‚¹ã‚­ãƒ¼ãƒã‚’è‡ªå‹•åˆ¤å®Efunction getSchemaForTableFallback(tableName: string): { schema: string; table: string } {
  const tableSchemaMap: Record<string, string> = {
    // master_data ã‚¹ã‚­ãƒ¼ãƒE    'managements_offices': 'master_data',
    'managements_offices': 'master_data',
    'bases': 'master_data',
    'machine_types': 'master_data',
    'machine-types': 'master_data', // ãƒã‚¤ãƒ•ãƒ³å½¢å¼ã‚‚ã‚µãƒï¿½EãƒE    'machines': 'master_data',
    'vehicles': 'master_data',
    'vehicle_types': 'master_data',
    'inspection_types': 'master_data',
    'maintenance_base_dates': 'master_data',
    'maintenance_plans': 'master_data',
    'inspection_schedules': 'master_data',
    'vehicle_inspection_schedules': 'master_data',
    
    // operations ã‚¹ã‚­ãƒ¼ãƒE    'operation_plans': 'operations',
    'operation_records': 'operations',
    'travel_plans': 'operations',
    'travel_records': 'operations',
    
    // inspections ã‚¹ã‚­ãƒ¼ãƒE    'inspection_plans': 'inspections',
    'inspections': 'inspections',
    'maintenance_cycles': 'inspections',
    'vehicle_inspection_records': 'inspections',
    'inspection_cycle_order': 'inspections',
    
    // maintenance ã‚¹ã‚­ãƒ¼ãƒE    'failures': 'maintenance',
    'repairs': 'maintenance',
    'monthly_maintenance_plans': 'maintenance',
  }
  
  // ãƒEï¿½Eãƒ–ãƒ«åã‚¨ã‚¤ãƒªã‚¢ã‚¹ï¿½Eï¿½å®Ÿéš›ã®DBãƒEï¿½Eãƒ–ãƒ«åã¸ã®å¤‰æ›ï¿½Eï¿½E  const tableNameAlias: Record<string, string> = {
    'managements_offices': 'managements_offices',
  }
  
  const actualTableName = tableNameAlias[tableName] || tableName
  const schema = tableSchemaMap[tableName] || tableSchemaMap[actualTableName] || 'public'
  // ãƒEï¿½Eãƒ–ãƒ«åï¿½Eãƒã‚¤ãƒ•ãƒ³ã‚’ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã«å¤‰æ›
  const physicalTable = actualTableName.replace(/-/g, '_')
  
  return { schema, table: physicalTable }
}

// ãƒEï¿½Eãƒ–ãƒ«åã‹ã‚‰ã‚¹ã‚­ãƒ¼ãƒã‚’è‡ªå‹•åˆ¤å®šï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ®‹ã™ï¿½Eï¿½Efunction getSchemaForTable(tableName: string): string {
  const { schema } = getSchemaForTableFallback(tableName)
  return schema
}

// SQLã‚¯ã‚¨ãƒªã«ã‚¹ã‚­ãƒ¼ãƒï¿½Eãƒ¬ãƒ•ã‚£ãƒEï¿½ï¿½ã‚¹ã‚’ï¿½Eå‹•è¿½åŠ 
function addSchemaPrefix(sql: string): string {
  // ã™ã§ã«ã‚¹ã‚­ãƒ¼ãƒï¿½Eãƒ¬ãƒ•ã‚£ãƒEï¿½ï¿½ã‚¹ãŒã‚ã‚‹å ´åˆï¿½Eãï¿½Eã¾ã¾è¿”ã™
  if (sql.match(/\b(master_data|operations|inspections|maintenance|public|information_schema)\./) ) {
    return sql
  }
  
  // ãƒEï¿½Eãƒ–ãƒ«åã‚’æ¤œï¿½Eã—ã¦ã‚¹ã‚­ãƒ¼ãƒï¿½Eãƒ¬ãƒ•ã‚£ãƒEï¿½ï¿½ã‚¹ã‚’è¿½åŠ 
  const tablePattern = /\b(FROM|JOIN|INTO|UPDATE|TABLE)\s+([a-z_]+)/gi
  const modifiedSql = sql.replace(tablePattern, (match, keyword, tableName) => {
    const schema = getSchemaForTable(tableName.toLowerCase())
    return `${keyword} ${schema}.${tableName}`
  })
  
  return modifiedSql
}

// æ±ç”¨ã‚¯ã‚¨ãƒªå®Ÿè¡Œé–¢æ•°
export async function executeQuery(sql: string, params: any[] = []): Promise<any> {
  try {
    // ã‚¹ã‚­ãƒ¼ãƒï¿½Eãƒ¬ãƒ•ã‚£ãƒEï¿½ï¿½ã‚¹ã‚’ï¿½Eå‹•è¿½åŠ 
    const modifiedSql = addSchemaPrefix(sql)
    console.log("Executing query:", modifiedSql, "with params:", params)
    
    // ãƒ—ï¿½Eãƒ«ãŒï¿½EæœŸåŒ–ã•ã‚Œã¦ãEï¿½ï¿½ã‹ç¢ºèªE    const pool = getPool()
    if (!pool) {
      console.error("âEDatabase pool is null!")
      throw new Error("Database connection is not available")
    }
    
    const result = await query(modifiedSql, params)
    console.log("Query result:", result.rows.length, "rows")
    return result.rows
  } catch (error) {
    console.error("âEQuery execution failed:", error)
    console.error("Error details:", {
      message: error instanceof Error ? error.message : 'Unknown error',
      code: (error as any).code,
      stack: error instanceof Error ? error.stack : undefined
    })
    throw error
  }
}

// Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¿½Eå–å¾—ï¼EostgreSQLã‚’ä½¿ç”¨ã™ã‚‹å ´åˆï¼Eexport function getSupabaseClient() {
  // ãƒEï¿½Eã‚¿ãƒ™ï¿½Eã‚¹ãŒè¨­å®šã•ã‚Œã¦ãEï¿½ï¿½ãEï¿½ï¿½åˆï¿½Enullã‚’è¿”ã™
  const databaseUrl = process.env.DATABASE_URL || process.env.POSTGRES_URL
  if (!databaseUrl) {
    return null
  }
  
  // ã“ï¿½Eãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯PostgreSQLã‚’ç›´æ¥ä½¿ç”¨ã—ã¦ãEï¿½ï¿½ãŸã‚ã€E  // Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¿½Eä»£ã‚ã‚Šã«PostgreSQLãƒ—ï¿½Eãƒ«ã‚’è¿”ã™
  return getPool()
}
